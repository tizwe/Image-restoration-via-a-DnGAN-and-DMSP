{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Restoration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOJ1i7+iBmvLBy5SOIw+zda",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tizwe/Image-restoration-via-a-DnGAN-and-DMSP/blob/main/Image_Restoration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa7dfXl4_YxR"
      },
      "source": [
        "\"\"\"\n",
        "Please ensure GPU and High RAM  enabled in the Runtime Settting\n",
        "\"\"\"\n",
        "\n",
        "!pip install tfa-nightly    #To allow us to import SpectralNormalization\n",
        "\n",
        "import numpy as np\n",
        "import time \n",
        "import itertools\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import tensorflow as tf \n",
        "import tensorflow_datasets as  tfds\n",
        "from tensorflow.data import Dataset as Set\n",
        "from tensorflow_addons.layers import SpectralNormalization\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input, Reshape\n",
        "from tensorflow.keras.layers import Lambda, LeakyReLU, PReLU, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.image import psnr\n",
        "from scipy import ndimage, signal as sig\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQXCYEDOIRss"
      },
      "source": [
        "#Hyperparaameters\n",
        "\n",
        "sigma=0.1\n",
        "BUFFER_SIZE = 60000\n",
        "batch_size = 8\n",
        "num_epochs = 50 \n",
        "num_examples_to_generate = 6"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIkZtdAhJU2E"
      },
      "source": [
        "\"\"\"\n",
        "Currently (19 Dec 2020) the website where our dataset was pulled from\n",
        "is down and hence the import fails. \n",
        "This will hopefully be resolved in a few days.\n",
        "\"\"\"\n",
        "\n",
        "#Import the lfw dataset which contains images of faces\n",
        "dataset = tfds.builder('lfw')\n",
        "dataset.download_and_prepare()\n",
        "dataset = dataset.as_dataset()\n",
        "dataset = dataset['train']\n",
        "\n",
        "# Converting Dataset to a NumPy Array\n",
        "\n",
        "lfw=[]\n",
        "\n",
        "for example in tfds.as_numpy(dataset):\n",
        "  image= example['image']\n",
        "  image=image[35:-35,35:-35,:]\n",
        "  lfw.append(image)\n",
        "\n",
        "lfw=np.array(lfw).astype(np.float32)\n",
        "\n",
        "\n",
        "# Split the data into traing set and test set which will be used for evaluation\n",
        "# We have to throw some parts of the dataet aways,\n",
        "# due to limited RAM capacity\n",
        "\n",
        "take_p=0.4 \n",
        "random.shuffle(lfw)\n",
        "(x_train,x_test,_)=np.split(lfw,[int(lfw.shape[0]*take_p),\n",
        "                                 int(lfw.shape[0]*(take_p+0.05))])\n",
        "\n",
        "\n",
        "# Bring the image date into the desired format for training\n",
        "\n",
        "im_dim1 = x_train[1].shape[0]     \n",
        "im_dim2 = x_train[1].shape[1]\n",
        "\n",
        "x_train = np.reshape(x_train, [-1, im_dim1, im_dim2, 3])\n",
        "x_test = np.reshape(x_test, [-1, im_dim1, im_dim2, 3])\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "\n",
        "# Create noisy images\n",
        "# Train Images\n",
        "noise=np.random.normal(loc=0,scale=sigma, size=x_train.shape).astype(np.float32)\n",
        "x_train_noisy = x_train + noise\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "del noise  \n",
        "#TestImages\n",
        "noise=np.random.normal(loc=0, scale=sigma, size=x_test.shape).astype(np.float32)\n",
        "x_test_noisy = x_test + noise\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "del noise #Delete Noise to free up Space in RAM \n",
        "\n",
        "\n",
        "# Split Dataset into Batches\n",
        "train_dataset_clean = Set.from_tensor_slices(x_train).batch(batch_size)\n",
        "train_dataset_noisy = Set.from_tensor_slices(x_train_noisy).batch(batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coB49KFxHDBG"
      },
      "source": [
        "\n",
        "\n",
        "# kernel size for the convolution\n",
        "kernel_size=3  \n",
        "l_pad,r_pad=int(np.floor((kernel_size-1)/2)),int(np.ceil((kernel_size-1)/2))\n",
        "\n",
        "# Scales the padding size withrespect to the kernel size\n",
        "pad_shape=([0,0],[l_pad,r_pad],[l_pad,r_pad],[0,0])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Manually pad before every Convolution to maintain the shape.\n",
        "This is because altought the Conv2D function can also perform \n",
        "shape-maintaing convolution, it does so by 0-padding. (Adding 0 at the borders)\n",
        "However, this created artifacts at the border of the images.\n",
        "With symmetric padding (duplicate border pixels)\n",
        "those artifacts can be reduced.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def make_generator_model(input_shape=(None,None,3)):\n",
        "\n",
        "    inpt= Input(shape=(input_shape[0],input_shape[1],input_shape[2]))\n",
        "    h0=   tf.pad(inpt,([0,0],[4,4],[4,4],[0,0]),'symmetric')\n",
        "    h0=   Conv2D(64,(9, 9),padding='valid')(h0)\n",
        "    out1= PReLU()(h0)\n",
        "\n",
        "\n",
        "    h1= tf.pad(out1,pad_shape,'symmetric')\n",
        "    h1= SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h1)\n",
        "    h1= BatchNormalization()(h1)\n",
        "    h1= PReLU()(h1)\n",
        "    h1= tf.pad(h1,pad_shape,'symmetric')\n",
        "    h1= SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h1)\n",
        "    h1= BatchNormalization()(h1)\n",
        "    out2=out1+h1\n",
        "\n",
        "    h2= tf.pad(out2,pad_shape,'symmetric')\n",
        "    h2= SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h2)\n",
        "    h2= BatchNormalization()(h2)\n",
        "    h2= PReLU()(h2)\n",
        "    h2= tf.pad(h2,pad_shape,'symmetric')\n",
        "    h2= SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h2)\n",
        "    h2= BatchNormalization()(h2)\n",
        "    out3= out2+h2\n",
        "\n",
        "    h3= tf.pad(out3,pad_shape,'symmetric')\n",
        "    h3= SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h3)\n",
        "    h3= BatchNormalization()(h3)\n",
        "    h3= PReLU()(h3)\n",
        "    h3= tf.pad(h3,pad_shape,'symmetric')\n",
        "    h3= SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h3)\n",
        "    h3= BatchNormalization()(h3)\n",
        "    out4=out3+h3\n",
        "\n",
        "    h4= tf.pad(out4,pad_shape,'symmetric')\n",
        "    h4= SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h4)\n",
        "    h4= BatchNormalization()(h4)\n",
        "    h4= PReLU()(h4)\n",
        "    h4= tf.pad(h4,pad_shape,'symmetric')\n",
        "    h4= SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h4)\n",
        "    h4= BatchNormalization()(h4)\n",
        "    out5=out4+h4\n",
        "\n",
        "\n",
        "    h5=tf.pad(out5,pad_shape,'symmetric')\n",
        "    h5=SpectralNormalization(\n",
        "        Conv2D(64,(kernel_size, kernel_size), padding='valid'))(h5)\n",
        "    h5=BatchNormalization()(h5)\n",
        "    out6=out1+h5\n",
        "\n",
        "    h6=tf.pad(out6,pad_shape,'symmetric')\n",
        "    h6=Conv2D(256,(kernel_size, kernel_size), padding='valid')(h6)\n",
        "    out7=PReLU()(h6)\n",
        "\n",
        "    h7=tf.pad(out7,pad_shape,'symmetric')\n",
        "    h7=Conv2D(256,(kernel_size, kernel_size), padding='valid')(h7)\n",
        "    out8=PReLU()(h7)\n",
        "\n",
        "    h8=tf.pad(out8,([0,0],[4,4],[4,4],[0,0]),'symmetric')\n",
        "    output=Conv2D(3,(9, 9), padding='valid',activation='sigmoid')(h8)\n",
        "    model=Model(inputs=[inpt], outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = make_generator_model(input_shape=(im_dim1,im_dim2,3))\n",
        "dae = make_generator_model(input_shape=(im_dim1,im_dim2,3))\n",
        "\n",
        "\n",
        "def make_discriminator_model(input_shape=(None,None,3)):\n",
        "  \n",
        "    inpt=Input(shape=(input_shape[0],input_shape[1],input_shape[2]))\n",
        "\n",
        "    h1= Reshape((im_dim1,im_dim2,3))(inpt)\n",
        "    h1= SpectralNormalization(Conv2D(64, (3, 3), strides=(1, 1)))(inpt)\n",
        "    out1= LeakyReLU()(h1)\n",
        "\n",
        "\n",
        "    h2= SpectralNormalization(Conv2D(64, (3, 3), strides=(2, 2)))(out1)\n",
        "    h2= LayerNormalization()(h2)\n",
        "    out2=LeakyReLU()(h2)\n",
        "\n",
        "    h3= SpectralNormalization(Conv2D(128, (3, 3), strides=(1, 1)))(out2)\n",
        "    h3= LayerNormalization()(h3)\n",
        "    out3=LeakyReLU()(h3)\n",
        "\n",
        "    h4= SpectralNormalization(Conv2D(128, (3, 3), strides=(2, 2)))(out3)\n",
        "    h4= LayerNormalization()(h4)\n",
        "    out4=LeakyReLU()(h4)\n",
        "\n",
        "    h5= SpectralNormalization(Conv2D(256, (3, 3), strides=(1, 1)))(out4)\n",
        "    h5= LayerNormalization()(h5)\n",
        "    out5=LeakyReLU()(h5)\n",
        "\n",
        "    h6= SpectralNormalization(Conv2D(256, (3, 3), strides=(2, 2)))(out5)\n",
        "    h6= LayerNormalization()(h6)\n",
        "    out6=LeakyReLU()(h6)\n",
        "    \n",
        "    h7= SpectralNormalization(Conv2D(256, (3, 3), strides=(1, 1)))(out6)\n",
        "    h7= LayerNormalization()(h7)\n",
        "    out7=LeakyReLU()(h7)\n",
        "\n",
        "    h8= SpectralNormalization(Conv2D(256, (3, 3), strides=(2, 2)))(out7)\n",
        "    h8= LayerNormalization()(h8)\n",
        "    out8=LeakyReLU()(h8)\n",
        "    \n",
        "\n",
        "    h9=Flatten()(out8)\n",
        "    h9=Dense(1024)(h9)\n",
        "    out9=LeakyReLU()(h9)\n",
        "  \n",
        "    output= Dense(1,activation='sigmoid')(out9)\n",
        "\n",
        "    model=Model(inputs=[inpt], outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "discriminator = make_discriminator_model(input_shape=(im_dim1,im_dim2,3))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBkrmFOdgclA"
      },
      "source": [
        "\"\"\"\n",
        "To import already trained models, uncomment the following lines:\n",
        "\"\"\"\n",
        "\n",
        "#generator=tf.keras.models.load_model('generator.h5') \n",
        "#discriminator=tf.keras.models.load_model('discriminator.h5')\n",
        "#dae=tf.keras.models.load_model('keras.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLqhh4V_BOee"
      },
      "source": [
        "#Seed for visualization\n",
        "inde=np.random.randint(x_test.shape[0],size=num_examples_to_generate)\n",
        "seed=x_test_noisy[0:num_examples_to_generate]\n",
        "seed_clear=x_test[0:num_examples_to_generate]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9OjaIDXBTsM"
      },
      "source": [
        "#Define the loss functions as the cross-entropy loss\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "\n",
        "    real_loss=tf.math.log(real_output)\n",
        "    fake_loss=tf.math.log(1.-fake_output)\n",
        "\n",
        "    return -tf.reduce_mean(real_loss+fake_loss)\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "\n",
        "    fake_loss=-tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        "    return fake_loss\n",
        "\n",
        "#Eucledian loss fot the DAE\n",
        "def dae_loss(gen_img,real_img):\n",
        "\n",
        "    e_loss=tf.reduce_mean(tf.nn.l2_loss(gen_img-real_img))\n",
        "\n",
        "    return  e_loss\n",
        "\n",
        "\n",
        "#Increasing learning rate naturally increases the training speed\n",
        "#But models are more likely to collaps then  \n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0000005)\n",
        "disc_optimizer = tf.keras.optimizers.Adam(0.0000005)\n",
        "dae_optimizer = tf.keras.optimizers.Adam(0.000001)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqW5F96c0pQ"
      },
      "source": [
        "#auxiliary functions\n",
        "\n",
        "def img_standardization(img):\n",
        "  return tf.image.per_image_standardization(img)\n",
        "\n",
        "def nrm(x):\n",
        "  return (x-np.min(x))/(np.ptp(x))\n",
        "\n",
        "def stan(x):\n",
        "  x=np.expand_dims(x,0)\n",
        "  x=tf.map_fn(lambda img: tf.image.per_image_standardization(img), x)\n",
        "  return x[0].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8VRPaqzHh3q"
      },
      "source": [
        "def train_step_dngan(clean_images,nsy_images):\n",
        "  \"\"\"\n",
        "  Implements a gradient descent step for the DnGAN \n",
        "  \"\"\"\n",
        "\n",
        "  # Take the first half of the clean images \n",
        "  # and the second half of the noisy images \n",
        "  # to ensure the dicriminator never sees \n",
        "  # both versions of the same image\n",
        "\n",
        "  half_size=(np.ceil(clean_images.shape[0] / 2)).astype(int)\n",
        "\n",
        "  real_images=clean_images[ :half_size]\n",
        "  noisy_images=nsy_images[-half_size: ]\n",
        "\n",
        "\n",
        "  # Gradient Step\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "    generated_images = generator(noisy_images, training=True)\n",
        "    generated_images = tf.map_fn(img_standardization, generated_images)\n",
        "    real_output = discriminator(real_images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output) \n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss,\n",
        "                                                generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator,\n",
        "                                            generator.trainable_variables))\n",
        "    gradients_of_disc = disc_tape.gradient(disc_loss,\n",
        "                                          discriminator.trainable_variables)\n",
        "    disc_optimizer.apply_gradients(zip(gradients_of_disc,\n",
        "                                       discriminator.trainable_variables))\n",
        "                                                \n",
        "\n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIfWAhnJmiIr"
      },
      "source": [
        "def train_step_dae(clean_images,nsy_images):\n",
        "  \"\"\"\n",
        "  Implements the gradient descent steps for the DAE \n",
        "  \"\"\"\n",
        "  real_images=clean_images\n",
        "  noisy_images=nsy_images\n",
        "\n",
        "  with tf.GradientTape() as dae_tape:\n",
        "    \n",
        "    generated_images = dae(noisy_images, training=True)\n",
        "    generated_images = tf.map_fn(img_standardization, generated_images)\n",
        "    dae_l = dae_loss(generated_images, real_images) \n",
        "    gradients_of_dae = dae_tape.gradient(dae_l, dae.trainable_variables)\n",
        "    dae_optimizer.apply_gradients(zip(gradients_of_dae, \n",
        "                                      dae.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB9ZTFgFHuwm"
      },
      "source": [
        "def train(clean_dataset, noisy_dataset, epochs=100):\n",
        "  \"\"\"\n",
        "  Start the training process\n",
        "  \"\"\"\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    start = time.time()\n",
        "    for img_batch_clean,img_batch_nsy in zip(clean_dataset,noisy_dataset):\n",
        "      \n",
        "      img_batch_clean=tf.map_fn(img_standardization,\n",
        "                              img_batch_clean)\n",
        "      img_batch_nsy=tf.map_fn(img_standardization,\n",
        "                             img_batch_nsy)\n",
        "      \n",
        "      img_batch_clean=tf.convert_to_tensor(img_batch_clean)\n",
        "      img_batch_nsy=tf.convert_to_tensor(img_batch_nsy)\n",
        "      train_step_dngan(img_batch_clean,img_batch_nsy)\n",
        "\n",
        "      #Since the DAE trains much faster, we only train it every second epoch\n",
        "      if epoch % 2 ==0:\n",
        "        train_step_dae(img_batch_clean,img_batch_nsy)\n",
        "\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    generate_images([generator,dae],\n",
        "                    epoch,\n",
        "                    seed)\n",
        "    \n",
        "    tm= time.time()-start\n",
        "\n",
        "    print (f'Time for epoch {epoch} is {tm} sec')\n",
        "\n",
        "    # Save the model every 5 epochs\n",
        "    if epoch%5==0:\n",
        "      generator.save('gen'+str(epoch)+'.h5')\n",
        "      discriminator.save('disc'+str(epoch)+'.h5')\n",
        "      dae.save('dae'+str(epoch)+'.h5')\n",
        "\n",
        "      \n",
        "  generator.save('generator.h5')\n",
        "  discriminator.save('discriminator.h5')\n",
        "  dae.save(('dae.h5'))\n",
        "\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  clear_output(wait=True)\n",
        "  generate_images([generator,dae],\n",
        "                  epochs,\n",
        "                  seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihntng93H1eJ"
      },
      "source": [
        "def generate_images(models, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "\n",
        "  #number of images used to evaluate the performance\n",
        "  #on the test set\n",
        "\n",
        "  sbtch=30  # Number is limited by RAM capacity\n",
        "\n",
        "  for model, ssim_hist, psnr_hist in zip(models,ssim_list,psnr_list): \n",
        "\n",
        "    predictions = model(tf.map_fn(img_standardization, \n",
        "                                  test_input), training=False)\n",
        "    predictions=tf.map_fn(nrm,predictions)\n",
        "\n",
        "    predictions2 = model(tf.map_fn(img_standardization, x_test_noisy[0:sbtch]),\n",
        "                        training=False)\n",
        "    predictions2=tf.map_fn(nrm,predictions2)\n",
        "  \n",
        "    ssim_val=np.mean([\n",
        "                  ssim(np.array(predictions2[i]),\n",
        "                        x_test[i],multichannel=True) \n",
        "                  for i in range(sbtch) \n",
        "                  ])\n",
        "    psnr_val=np.mean([\n",
        "                  psnr(np.array(predictions2[i]),\n",
        "                      x_test[i],1)\n",
        "                  for i in range(sbtch)\n",
        "                  ])\n",
        "        \n",
        "    ssim_hist.append(ssim_val)\n",
        "    psnr_hist.append(psnr_val)\n",
        "\n",
        "    #Plot (Epoh,SSIM) and (Epoch,PSNR) in the same graph \n",
        "    fig,ax1 = plt.subplots()\n",
        "    ax1.plot(ssim_hist,label='\\n ssim')\n",
        "    plt.legend(loc='upper left')\n",
        "    ax1.tick_params(axis='y')\n",
        "    ax2 = ax1.twinx()  \n",
        "    ax2.plot(psnr_hist,color='r',label='psnr')\n",
        "    ax2.tick_params(axis='y')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.savefig('psnrh_hist.png')\n",
        "    plt.show()\n",
        "\n",
        "    fig = plt.figure(figsize=(80,80))\n",
        "    for i in range(4):\n",
        "        plt.subplot(4, 3, i*3+1)\n",
        "        plt.imshow((predictions[i][:, :, :]))\n",
        "        plt.axis('off')\n",
        "        plt.subplot(4, 3, i*3+2)\n",
        "        plt.imshow((seed[i, :, :,:]))\n",
        "        plt.axis('off')\n",
        "        plt.subplot(4, 3, i*3+3)\n",
        "        plt.imshow(np.clip(seed_clear[i],0,1))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciroqqpj1Nrb",
        "outputId": "efb10750-2552-4187-cdb3-05dbb46149e6"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-c9328b96-4cf0-0d22-d40b-9a021ea2fd42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGG2lPVF36Zy"
      },
      "source": [
        "#Lists where we will save the progress during training\n",
        "\n",
        "ssim_dae_hist=[]\n",
        "psnr_dae_hist=[]\n",
        "ssim_dngan_hist=[]\n",
        "psnr_dngan_hist=[]\n",
        "\n",
        "ssim_list=[ssim_dae_hist,ssim_dngan_hist]\n",
        "psnr_list=[psnr_dae_hist,psnr_dngan_hist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmqZPh1DH5ZU"
      },
      "source": [
        "\"\"\"\n",
        "This may take a while.\n",
        "To speed things up, consider decreasing the number of training images instead of \n",
        "lowerig the number of epochs.\n",
        "If OOM errors occur, lower the Batch size.\n",
        "To continue training, run this cell again.\n",
        "\"\"\"\n",
        "#Note: Throws warnings since Tensorflow 2.4 \n",
        "#These can be ignored and might likely go away with further updates. \n",
        "\n",
        "train(train_dataset_clean,\n",
        "      train_dataset_noisy,\n",
        "      200)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vHJylru10md"
      },
      "source": [
        "# Deblur\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nj1rrLN1_AS"
      },
      "source": [
        "The following work, is a derivative of [Deep Mean-Shift Priors for Image Restoration](https://github.com/siavashBigdeli/DMSP-tensorflow#deep-mean-shift-priors-for-image-restoration-project-page) by Bigdelli et al., used under CC BY-NC-SA 4.0. This work is hence also licensed under CC BY-NC-SA 4.0 by Tizian Weber."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHP9K9gBIqyl"
      },
      "source": [
        "# Adjust the denoiser to fit in the needed Input/Output format\n",
        "\n",
        "\n",
        "def den_dae(x):\n",
        "  x=np.expand_dims(x,0)\n",
        "  x=tf.map_fn(lambda img: tf.image.per_image_standardization(img), x)\n",
        "  x=dae(x)\n",
        "  x=x[0]\n",
        "  return x\n",
        "\n",
        "def den_dngan(x):\n",
        "  x=np.expand_dims(x,0)\n",
        "  x=tf.map_fn(lambda img: tf.image.per_image_standardization(img), x)\n",
        "  x=generator(x)\n",
        "  x=x[0]\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyYFGPLNNk5p"
      },
      "source": [
        "def computePSNR(img1, img2, pad_y, pad_x):\n",
        "    \"\"\" Computes peak signal-to-noise ratio between two images. \n",
        "    Input:\n",
        "    img1: First image in range of [0, 255].\n",
        "    img2: Second image in range of [0, 255].\n",
        "    pad_y: Scalar radius to exclude boundaries from contributing to PSNR computation in vertical direction.\n",
        "    pad_x: Scalar radius to exclude boundaries from contributing to PSNR computation in horizontal direction.\n",
        "    \n",
        "    Output: PSNR \"\"\"\n",
        "\n",
        "    # Crop the edges away that were added by padding\n",
        "    # '...or  None' to catch the '-0' Case.\n",
        "    img1=img1[pad_y:-pad_y or None,\n",
        "              pad_x:-pad_x or None,\n",
        "              :]\n",
        "\n",
        "    img2=img2[pad_y:-pad_y or None,\n",
        "              pad_x:-pad_x or None,\n",
        "              :]\n",
        "    img1=nrm(stan(img1))\n",
        "    img2=nrm(stan(img2))\n",
        "    psnr=tf.image.psnr(img1,img2,1)\n",
        "    ssm=ssim(img1,img2,multichannel=True)\n",
        "    return psnr,ssm\n",
        "\n",
        "def filter_image(image, kernel, mode='valid'):\n",
        "    \"\"\" Implements color filtering (convolution using a flipped kernel) \"\"\"\n",
        "    chs = []\n",
        "    for d in range(image.shape[2]):\n",
        "        channel = sig.convolve2d(image[:,:,d], \n",
        "                                 np.flipud(np.fliplr(kernel)), mode=mode)\n",
        "        chs.append(channel)\n",
        "    return np.stack(chs, axis=2)\n",
        "\n",
        "def convolve_image(image, kernel, mode='valid'):\n",
        "    \"\"\" Implements color image convolution \"\"\"\n",
        "    chs = []\n",
        "    for d in range(image.shape[2]):\n",
        "        channel = sig.convolve2d(image[:,:,d], kernel, mode=mode)\n",
        "        chs.append(channel)\n",
        "    return np.stack(chs, axis=2)\n",
        "\n",
        "def DMSPDeblur(degraded, kernel, sigma_d, params):\n",
        "    \"\"\" Implements stochastic gradient descent (SGD) \n",
        "    Bayes risk minimization for image deblurring described in:\n",
        "     \"Deep Mean-Shift Priors for Image Restoration\" \n",
        "     (http://home.inf.unibe.ch/~bigdeli/DMSPrior.html)\n",
        "     S. A. Bigdeli, M. Jin, P. Favaro, M. Zwicker, \n",
        "     Advances in Neural Information Processing Systems (NIPS), 2017 \n",
        "     \n",
        "     Input:\n",
        "     degraded: Observed degraded RGB input image in range of [0, 255].\n",
        "     kernel: Blur kernel (internally flipped for convolution).\n",
        "     sigma_d: Noise standard deviation. (set to -1 for noise-blind deblurring)\n",
        "     params: Set of parameters.\n",
        "     params.denoiser: The denoiser function hanlde.\n",
        "    \n",
        "     Optional parameters:\n",
        "     params.sigma_dae:  The Standard deviation of the denoiser \n",
        "                        training noise. default: 11\n",
        "     params.num_iter: Specifies number of iterations.\n",
        "     params.mu: The momentum for SGD optimization. default: 0.9\n",
        "     params.alpha the step length in SGD optimization. default: 0.1\n",
        "    \n",
        "     Outputs:\n",
        "     res: Solution.\"\"\"\n",
        "\n",
        "\n",
        "    if 'denoiser' not in params:\n",
        "        raise ValueError('Need a denoiser in params.denoiser!')\n",
        "        \n",
        "    if 'gt' in params and params['print'] is True:\n",
        "        print_iter = True\n",
        "    else:\n",
        "        print_iter = False\n",
        "    \n",
        "    if 'sigma_dae' not in params:\n",
        "        params['sigma_dae'] = 11.0\n",
        "\n",
        "    if 'num_iter' not in params:\n",
        "        params['num_iter'] = 10\n",
        "        \n",
        "    if 'mu' not in params:\n",
        "        params['mu'] = 0.9\n",
        "    \n",
        "    if 'alpha' not in params:\n",
        "        params['alpha'] = 0.1\n",
        "\n",
        "    sigma_dae=params['sigma_dae']\n",
        "\n",
        "\n",
        "    pad_y = np.floor(kernel.shape[0] / 2.0).astype(np.int64)\n",
        "    pad_x = np.floor(kernel.shape[1] / 2.0).astype(np.int64)\n",
        "    res = np.pad(degraded, pad_width=((pad_y, pad_y), (pad_x, pad_x), (0, 0)), \n",
        "                 mode='edge')\n",
        "    step = np.zeros(res.shape)\n",
        "\n",
        "    # Calculate some expressions now \n",
        "    # to avoid redundant calculations in the loop\n",
        "\n",
        "    sigma_sq = sigma_dae**2\n",
        "    if  sigma_d >= 0:\n",
        "        relative_weight = (1/ sigma_d**2 ) / ( 1/ sigma_d**2 + 1/ sigma_sq)\n",
        "    term=degraded.size * 2*sigma_sq * (np.sum(np.power(kernel[:], 2)))\n",
        "    \n",
        "\n",
        "    histp=[]    # PSNR Hist\n",
        "    hists=[]    # SSIM Hist\n",
        "\n",
        "    if print_iter:\n",
        "        psnr,ssm = computePSNR(params['gt'], res, pad_y, pad_x)\n",
        "        print(f'Initialized with PSNR: {psnr:.4f} SSIM : {ssm:.4f} ' )\n",
        "\n",
        "    for iter in range(params['num_iter']):\n",
        "        if print_iter:\n",
        "            t = time.time()\n",
        "\n",
        "        #     compute prior gradient\n",
        "        noise = np.random.normal(0.0,sigma_dae, res.shape).astype(np.float32)\n",
        "        rec = params['denoiser'](res + noise)\n",
        "        rec=rec.numpy()\n",
        "        rec=nrm(rec)\n",
        "        prior_grad = res - rec\n",
        "\n",
        "        #     compute data gradient\n",
        "        map_conv = filter_image(res, kernel)\n",
        "        data_err = map_conv - degraded\n",
        "        data_grad = convolve_image(data_err, kernel, mode='full')\n",
        "\n",
        "        if sigma_d < 0:\n",
        "            lambda_ = (degraded.size) / (\n",
        "                        np.sum(np.power(data_err[:], 2)) + term)\n",
        "            relative_weight = lambda_ / (lambda_ + 1 / sigma_sq)\n",
        "\n",
        "        #     sum the gradients\n",
        "\n",
        "        grad_joint = data_grad * relative_weight + prior_grad * (1 - relative_weight)\n",
        "\n",
        "        #     update\n",
        "        step = params['mu'] * step - params['alpha'] * grad_joint\n",
        "        res = res + step\n",
        "        res = np.minimum(1.0, np.maximum(0, res)).astype(np.float32)\n",
        "\n",
        "        if print_iter:\n",
        "            \n",
        "            psnr,ssm  = computePSNR(params['gt'], res, pad_y, pad_x)\n",
        "            hists.append(ssm)\n",
        "            histp.append(psnr)\n",
        "            it_time=time.time()-t\n",
        "            if iter % 5 == 0:\n",
        "              print('Finished iteration: ' + str(iter))\n",
        "              print (f'PSNR: {psnr:.4f}, SSIM: {ssm:.4f}, iteration finished in {it_time} seconds')\n",
        "                   \n",
        "\n",
        "\n",
        "\n",
        "    #Plot the PSNR and SSIM Values over epochs \n",
        "    fig,ax1 = plt.subplots()\n",
        "    ax1.plot(histp,label='psnr')\n",
        "    ax1.tick_params(axis='y')\n",
        "    ax2 = ax1.twinx()  \n",
        "    ax2.plot(hists,color='r',label='ssim')\n",
        "    ax2.tick_params(axis='y')\n",
        "    fig.legend()\n",
        "    plt.show()\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfho6KPCObvz"
      },
      "source": [
        "def deblur_setup(gt,sigma_d,denoiser,num_iter=100,print_iter=True):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "  gt: The ground truth image \n",
        "  sigma_d: The SD of the noise to be added \n",
        "  denoiser: The denoiser used in the DMSP \n",
        "  num_iter: Number of iterations\n",
        "  print_iter: whether intermed. results should be printed. default: True\n",
        "  Output: \n",
        "\n",
        "  psnrvalues: PSNR values of the results\n",
        "  ssimvalues: SSIM values of the results \n",
        "  im: Images normalized to [0,1]      \n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # The DMSP deblur function and the RGB filtering function (flipped convolution)\n",
        "  # The denoiser implementation\n",
        "\n",
        "\n",
        "  denoise = denoiser\n",
        "\n",
        "\n",
        "  # Load data\n",
        "  sigma_d = sigma_d/255\n",
        "\n",
        "  # Load kernel (kernels.mat must be in the same directory as this notebook)\n",
        "  # If running on Colab, just drag-drop kernels.mat  in the folder symbol on the right \n",
        "  ms = sio.loadmat('kernels.mat')\n",
        "  k=ms['kernels']\n",
        "  kernel=k[0][1]  # Choose a kernel\n",
        "  k_dec=7  # Decrease the kernel size\n",
        "  kernel=kernel[k_dec:-k_dec, k_dec:-k_dec]\n",
        "  kernel= kernel/np.sum(kernel)\n",
        "  degraded = filter_image(gt, kernel)\n",
        "  noise = np.random.normal(0.0, sigma_d, degraded.shape).astype(np.float32)\n",
        "  degraded = degraded + noise\n",
        "  degraded=np.clip(degraded,0,1)\n",
        "\n",
        "\n",
        "\n",
        "  # non-blind deblurring\n",
        "  # run DMSP\n",
        "\n",
        "  params = {}\n",
        "  params['denoiser'] = denoise\n",
        "  params['sigma_dae'] = 0.1\n",
        "  params['num_iter'] = num_iter\n",
        "  params['mu'] = 0.8\n",
        "  params['alpha'] = 0.03\n",
        "  params['gt'] = gt # feed ground truth to monitor the PSNR at each iteration\n",
        "  params['print'] = print_iter\n",
        "  restored = DMSPDeblur(degraded, kernel, sigma_d, params)\n",
        "\n",
        "  img_restored = Image.fromarray((np.clip(restored, 0, 1)*255).astype(dtype=np.uint8))\n",
        "\n",
        "\n",
        "  # noise-blind deblurring\n",
        "  # run DMSP noise-blind\n",
        "\n",
        "  params = {}\n",
        "  params['denoiser'] = denoise\n",
        "  params['sigma_dae'] = 0.1\n",
        "  params['num_iter'] = num_iter\n",
        "  params['mu'] = 0.8\n",
        "  params['alpha'] = 0.03\n",
        "  params['gt'] = gt\n",
        "  params['print'] = print_iter\n",
        "\n",
        "  restored_nb = DMSPDeblur(degraded, kernel, -1, params)\n",
        "\n",
        "\n",
        "  # Generate the images and calculate PSNR/SSIM\n",
        "  \n",
        "  img_degraded = Image.fromarray((np.clip(degraded, 0, 1)*255).astype(dtype=np.uint8))\n",
        "  img_restored_nb = Image.fromarray((np.clip(restored_nb, 0, 1)*255).astype(dtype=np.uint8))\n",
        "\n",
        "  psnrvalues=[]\n",
        "  ssimvalues=[]\n",
        "\n",
        "  pad_y = np.floor(kernel.shape[0] / 2.0).astype(np.int64)\n",
        "  pad_x = np.floor(kernel.shape[1] / 2.0).astype(np.int64)\n",
        "  psnr, ssim = computePSNR(gt, \n",
        "                   np.pad(degraded, pad_width=((pad_y, pad_y), (pad_x, pad_x), (0, 0)), mode='edge').astype(np.float32), \n",
        "                   pad_y, pad_x)  \n",
        "  \n",
        "  psnrvalues.append(psnr)\n",
        "  ssimvalues.append(ssim)\n",
        "\n",
        "  psnr, ssim = computePSNR(gt, restored, pad_y, pad_x)\n",
        "  psnrvalues.append(psnr)\n",
        "  ssimvalues.append(ssim)\n",
        "\n",
        "  psnr, ssim = computePSNR(gt, restored_nb, pad_y, pad_x)\n",
        "  psnrvalues.append(psnr)\n",
        "  ssimvalues.append(ssim)\n",
        "\n",
        "  psnr, ssim = computePSNR(gt,denoise(restored), pad_y, pad_x)\n",
        "  psnrvalues.append(psnr)\n",
        "  ssimvalues.append(ssim)\n",
        "\n",
        "  psnr, ssim = computePSNR(gt, denoise(restored_nb), pad_y, pad_x)\n",
        "  psnrvalues.append(psnr)\n",
        "  ssimvalues.append(ssim)\n",
        "\n",
        "  im=[] \n",
        "  im.append(gt)\n",
        "  im.append(degraded)\n",
        "  im.append(restored)\n",
        "  im.append(restored_nb)\n",
        "  im.append(nrm(denoise(restored)))\n",
        "  im.append(nrm(denoise(restored_nb)))\n",
        "\n",
        "  return psnrvalues,ssimvalues, im "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IGLlqocA0qX"
      },
      "source": [
        "im=random.choice(x_train) #Pick a random image to test \n",
        "sigm=5 \n",
        "\n",
        "print(\"Start deblurring with DAE\")\n",
        "dae_p,dae_s,im_dae=deblur_setup(im,sigm,den_dae,200)\n",
        "print(\"Start deblurring with DnGAN\")\n",
        "dngan_p,dngan_s,im_dngan=deblur_setup(im,sigm,den_dngan,200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD_UVLkDBg3q"
      },
      "source": [
        "\"\"\"\n",
        "Print and show results \n",
        "\"\"\"\n",
        "\n",
        "print(f'Degraded: \\t PSNR: {dae_p[0]} , SSIM: {dae_s[0]}')\n",
        "print(f'DAE: \\t PSNR: {dae_p[1]} , SSIM: {dae_s[1]}')\n",
        "print(f'DAE na: \\t PSNR: {dae_p[2]} , SSIM: {dae_s[2]}')\n",
        "print(f'DnGAN: \\t PSNR: {dngan_p[1]} , SSIM: {dngan_s[1]}')\n",
        "print(f'DnGAN na: \\t PSNR: {dngan_p[2]} , SSIM: {dngan_s[2]}')\n",
        "print(f'DAE +: \\t PSNR: {dae_p[3]} , SSIM: {dae_s[3]}')\n",
        "print(f'DAE na+: \\t PSNR: {dae_p[4]} , SSIM: {dae_s[4]}')\n",
        "\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, constrained_layout=False, figsize=(40, 20))\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "\n",
        "ax=axes[0,0]\n",
        "ax.axis('Off')\n",
        "ax.set_title('Original',fontsize=50)\n",
        "ax.imshow(im_dngan[0])\n",
        "\n",
        "ax=axes[0,1]\n",
        "ax.axis('Off')\n",
        "ax.set_title('Degraded',fontsize=50)\n",
        "ax.imshow(im_dngan[1])\n",
        "\n",
        "\n",
        "ax=axes[0,2]\n",
        "ax.axis('Off')\n",
        "ax.set_title('DAE',fontsize=50)\n",
        "ax.imshow(im_dae[2])\n",
        "\n",
        "ax=axes[0,3]\n",
        "ax.axis('Off')\n",
        "ax.set_title('DAE na',fontsize=50)\n",
        "ax.imshow(im_dae[3])\n",
        "\n",
        "ax=axes[1,0]\n",
        "ax.axis('Off')\n",
        "ax.set_title('DGAN',fontsize=50,y=-0.1)\n",
        "ax.imshow(im_dngan[2])\n",
        "\n",
        "ax=axes[1,1]\n",
        "ax.axis('Off')\n",
        "ax.set_title('DGAN na',fontsize=50,y=-0.1)\n",
        "ax.imshow(im_dngan[3])\n",
        "\n",
        "ax=axes[1,2]\n",
        "ax.axis('Off')\n",
        "ax.set_title('DAE +',fontsize=50,y=-0.1)\n",
        "ax.imshow(im_dae[4])\n",
        "\n",
        "ax=axes[1,3]\n",
        "ax.axis('Off')\n",
        "ax.set_title('DAE na +',fontsize=50,y=-0.1)\n",
        "ax.imshow(im_dae[5])\n",
        "plt.savefig('results_deblur_sig' + str(sigm) + '.png')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}